{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christianbeynis/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.83118451728382e-05 , 0.9994382180275835\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('data_challenge_dataset.csv', encoding='Latin-1')\n",
    "\n",
    "\n",
    "df1 = df.fillna(-300)\n",
    "\n",
    "#fillna I do not know the meaning of the missing values so I make them outliers\n",
    "#after Checking the min and max values for the columns\n",
    "\n",
    "#Note for the class the average value is 1.72%, the class could ne a diagnosis\n",
    "#In that case maybe some missing values can be deliberately hidden\n",
    "\n",
    "X = df1.loc[:,df1.columns != 'Class'] # Trainning columns\n",
    "y = df1.Class #testing columns\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0) # split for trainning\n",
    "\n",
    "# Random forest most sensitive variable\n",
    "clf = RandomForestClassifier(n_estimators=10, random_state=0, n_jobs=-1)\n",
    "#Note we can do a cross validation for the best accuracies\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "sfm = SelectFromModel(clf, threshold=0.06)\n",
    "sfm.fit(X_train, y_train)\n",
    "\n",
    "#give important variables for noise reduction\n",
    "#for feature_list_index in sfm.get_support(indices=True):\n",
    "    #print(df1.columns[feature_list_index])\n",
    "    \n",
    "\n",
    "X_important_train = sfm.transform(X_train)\n",
    "X_important_test = sfm.transform(X_test)\n",
    "\n",
    "\n",
    "clf_important = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "clf_important.fit(X_important_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "y_important_pred = clf_important.predict(X_important_test)\n",
    "\n",
    "#Here we let the random forest classifier operate with all the variable versus \n",
    "#random forest with the variables with the threshold above .06 and see the difference\n",
    "#between accuracy scores.\n",
    "\n",
    "print(accuracy_score(y_test, y_important_pred)- accuracy_score(y_test, y_pred),',', accuracy_score(y_test, y_important_pred))\n",
    "\n",
    "#The difference in accuracy score is small enough, we can just use the variables selected from\n",
    "#threshold value for fitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christianbeynis/anaconda3/lib/python3.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/christianbeynis/anaconda3/lib/python3.7/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "/Users/christianbeynis/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3790: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.7818960118963864 , accuracy: 0.9982584677324969\n"
     ]
    }
   ],
   "source": [
    "#We do our fitting with logistic regression 1st\n",
    "#Note that we do not include class weight balanced in the logreg to account for the occurence of cases\n",
    "#Since the class is either 0, 1 we use logistic regression \n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "  \n",
    "\n",
    "\n",
    "# The important features are V2, V10, V11, V14, V17\n",
    "# We can use df with the following features for the classifications\n",
    "\n",
    "df2 = df[['V2', 'V10', 'V11', 'V14', 'V17','Class']]\n",
    "\n",
    "df2.fillna(-300, inplace = True)#somehow fillna method pad did not work. I used outlier -300\n",
    "\n",
    "X2 = df2.loc[:,df2.columns != 'Class'] # Trainning columns\n",
    "y2 = df2.Class #testing columns\n",
    "\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.25, random_state=0) # split for trainning\n",
    "\n",
    "scaler = MinMaxScaler() #for scaling\n",
    "\n",
    "X_train_Scl = scaler.fit_transform(X_train2) #scaling the data since we distance and the weight \n",
    "X_test_Scl = scaler.transform(X_test2)# can have an effect on the regression\n",
    "\n",
    "#We operate a gridsearch to optimize AUC\n",
    "\n",
    "\n",
    "lr = LogisticRegression(penalty='l1', class_weight = 'balanced', max_iter=40, tol=10) #We use L1 because we have\n",
    "                                                           #already done feature selection\n",
    "\n",
    "\n",
    "grid = { 'C': np.power(10.0, np.arange(-100, 100)), 'solver': ['liblinear'] }\n",
    "\n",
    "grid_AUC_scores = GridSearchCV(lr, param_grid = grid, scoring = 'roc_auc')\n",
    "grid_AUC_scores.fit(X_train_Scl, y_train2)\n",
    "\n",
    "Accuracy = GridSearchCV(lr, grid, scoring='accuracy')\n",
    "Accuracy.fit(X_train_Scl, y_train2)\n",
    "\n",
    "#optimize the scores ROC: sensitivity and AUC: should be above .5 and closer to 1\n",
    "#to differentiate from a dummy classifier. In order to optimize our classification\n",
    "print( 'AUC:', grid_AUC_scores.best_score_ ,', accuracy:', Accuracy.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.5417902316797034 , accuracy: 0.9982584677324969\n"
     ]
    }
   ],
   "source": [
    "#We use logistic regression on the entire set with L2 regularization ans sag solver and gridsearch\n",
    "#We have used the logistic model without class_weight = 'balanced' the AUC ROC is .53 \n",
    "#However class_weight = 'balanced' there is a slight improvement in AUC .54-.55\n",
    "\n",
    "from sklearn import cross_validation\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df1.fillna(-300, inplace = True)#somehow fillna method pad did not work. I used outlier -300\n",
    "\n",
    "\n",
    "X_train_Scl1 = scaler.fit_transform(X_train) #scaling the data since we distance and the weight \n",
    "X_test_Scl1 = scaler.transform(X_test)# can have an effect on the regression\n",
    "\n",
    "#We operate a gridsearch to optimize AUC\n",
    "\n",
    "\n",
    "lr2 = LogisticRegression(penalty='l2',class_weight = 'balanced', max_iter=40, tol=10) #We use L2\n",
    "#class weigth to account for the fact that the target classes do not have the same weight\n",
    "#It is a way around touching the threshold probability\n",
    "\n",
    "grid1 = { 'C': np.power(10.0, np.arange(-10, 10)), 'solver': ['sag'] }\n",
    "\n",
    "grid_AUC_scores1 = GridSearchCV(lr2, param_grid = grid1, scoring = 'roc_auc')\n",
    "grid_AUC_scores1.fit(X_train_Scl1, y_train)\n",
    "\n",
    "Accuracy1 = GridSearchCV(lr2, grid1, scoring='accuracy')\n",
    "Accuracy1.fit(X_train_Scl1, y_train)\n",
    "\n",
    "#optimize the scores ROC: sensitivity and AUC: should be above .5 and closer to 1\n",
    "#to differentiate from a dummy classifier. In order to optimize our classification\n",
    "print( 'AUC:', grid_AUC_scores1.best_score_ ,', accuracy:', Accuracy1.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.5 , accuracy: 0.9983146540827504\n"
     ]
    }
   ],
   "source": [
    "# we do a linear regression on the filtered set\n",
    "#The model behaves badly. The relationship is very likely nonlinear and a gridsearch will likely not improve the \n",
    "#scores so much\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "linreg = linear_model.Lasso(alpha=.5)\n",
    "linreg.fit(X_train_Scl, y_train2)\n",
    "PredLinY = linreg.predict(X_test_Scl) \n",
    "print('AUC:', roc_auc_score(y_test2, PredLinY.round()), ', accuracy:', accuracy_score(y_test2, PredLinY.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 10} , AUC: 0.9137948109075315\n"
     ]
    }
   ],
   "source": [
    "#We use SVC on the filtered set with a 5 fold cross validation (data split in 5)\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "\n",
    "Cs = [0.1, 1, 10] #C values for simplicity of model\n",
    "gammas = [0.01, 1, 10] #We will trade off the influence far or close of the model with C\n",
    "nfolds = 5\n",
    "grid2 = {'C': Cs, 'gamma' : gammas}\n",
    "grid_search = GridSearchCV(svm.SVC(kernel='rbf'), grid2, cv=nfolds)\n",
    "grid_search.fit(X_train_Scl, y_train2)\n",
    "grid_search_AUC = GridSearchCV(svm.SVC(kernel='rbf'), grid2, cv=nfolds, scoring='roc_auc')\n",
    "grid_search_AUC.fit(X_train_Scl, y_train2)\n",
    "print(grid_search.best_params_,', AUC:', grid_search_AUC.best_score_) # best parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9990449706468919 , F1 score: 0.6458333333333335\n"
     ]
    }
   ],
   "source": [
    "#accuracy for selected parameters\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "\n",
    "model = svm.SVC(kernel='rbf', gamma = 10, C = 10)\n",
    "model.fit(X_train_Scl, y_train2)\n",
    "PredY = model.predict(X_test_Scl)\n",
    "print('accuracy:',accuracy_score(y_test2, PredY),', F1 score:', skm.f1_score(y_test2, PredY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.6660534371271403\n"
     ]
    }
   ],
   "source": [
    "#We use neural network MLP on entire set with l2 regularization \n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "MLP = MLPClassifier(alpha = 5, random_state = 0, \n",
    "                    solver = 'lbfgs') #l2 penalization with alpa = 5 on entire set\n",
    "\n",
    "#MLP.fit(X_train_Scl, y_train)\n",
    "\n",
    "\n",
    "grid_values = {'hidden_layer_sizes': [[7, 4], [30, 20]]} #layers node or neurons and layers\n",
    "\n",
    "grid_AUC_scores = GridSearchCV(MLP, param_grid = grid_values, scoring = 'roc_auc')\n",
    "#grid_Acc_scores = GridSearchCV(MLP, param_grid = grid_values, scoring = 'accuracy')\n",
    "\n",
    "\n",
    "\n",
    "grid_AUC_scores.fit(X_train_Scl, y_train2)\n",
    "#grid_Acc_scores.fit(X_train_Scl1, y_train)\n",
    "\n",
    "#print('AUC:',grid_AUC_scores.best_score_,', accuracy:', grid_Acc_scores.best_score_)\n",
    "print('AUC:',grid_AUC_scores.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
